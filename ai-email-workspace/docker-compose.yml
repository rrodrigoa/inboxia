version: '3.9'

services:
  db:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: inboxia
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  backend:
    build: ./backend
    environment:
      DATABASE_URL: postgresql+psycopg2://postgres:postgres@db:5432/inboxia
      REDIS_URL: redis://redis:6379/0
      LLM_PROVIDER: openai_compatible
      OPENAI_BASE_URL: http://host.docker.internal:${LLM_PORT:-8001}/v1
      OPENAI_CHAT_MODEL: ${OPENAI_CHAT_MODEL:-chat}
      OPENAI_EMBEDDING_MODEL: ${OPENAI_EMBEDDING_MODEL:-embedding}
      FRONTEND_BACKEND_URL: http://localhost:${BACKEND_PORT:-8000}
    depends_on:
      - db
      - redis
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./backend:/app

  worker:
    build: ./backend
    command: ["celery", "-A", "app.tasks.celery_app", "worker", "--loglevel=info"]
    environment:
      DATABASE_URL: postgresql+psycopg2://postgres:postgres@db:5432/inboxia
      REDIS_URL: redis://redis:6379/0
      LLM_PROVIDER: openai_compatible
      OPENAI_BASE_URL: http://host.docker.internal:${LLM_PORT:-8001}/v1
      OPENAI_CHAT_MODEL: ${OPENAI_CHAT_MODEL:-chat}
      OPENAI_EMBEDDING_MODEL: ${OPENAI_EMBEDDING_MODEL:-embedding}
    depends_on:
      - db
      - redis
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./backend:/app

  frontend:
    build: ./frontend
    environment:
      NEXT_PUBLIC_BACKEND_URL: http://localhost:${BACKEND_PORT:-8000}
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  db_data:
